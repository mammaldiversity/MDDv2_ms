higher_continent = Higher_continent,
higher_biogeographic_realm = Higher_biorealm)
# Create a look-up table for ANSI codes to state names
state_lookup <- c(
AL = "Alabama", AK = "Alaska", AZ = "Arizona", AR = "Arkansas", CA = "California",
CO = "Colorado", CT = "Connecticut", DE = "Delaware", DC = "District of Columbia", FL = "Florida", GA = "Georgia (United States)",
HI = "Hawaii", ID = "Idaho", IL = "Illinois", IN = "Indiana", IA = "Iowa",
KS = "Kansas", KY = "Kentucky", LA = "Louisiana", ME = "Maine", MD = "Maryland",
MA = "Massachusetts", MI = "Michigan", MN = "Minnesota", MS = "Mississippi", MO = "Missouri",
MT = "Montana", NE = "Nebraska", NV = "Nevada", NH = "New Hampshire", NJ = "New Jersey",
NM = "New Mexico", NY = "New York", NC = "North Carolina", ND = "North Dakota", OH = "Ohio",
OK = "Oklahoma", OR = "Oregon", PA = "Pennsylvania", RI = "Rhode Island", SC = "South Carolina",
SD = "South Dakota", TN = "Tennessee", TX = "Texas", UT = "Utah", VT = "Vermont",
VA = "Virginia", WA = "Washington", WV = "West Virginia", WI = "Wisconsin", WY = "Wyoming"
)
# Process subregionDistribution for US states
subregion_df <- species_df %>%
filter(!is.na(subregionDistribution)) %>%
mutate(states_list = str_extract(subregionDistribution, "(?<=USA\\().*(?=\\))")) %>%
separate_rows(states_list, sep = ",") %>%
mutate(states_list = str_trim(states_list)) %>%
mutate(
regions_clean = state_lookup[str_replace(states_list, "\\?$", "")],  # Convert ANSI codes to state names
possible = str_detect(states_list, "\\?$"),  # Identify possible occurrences
sciName = sciName,  # Retain the species name for later grouping
extinct = extinct,  # Include the extinct column
diffSinceMSW3 = diffSinceMSW3,  # Include the diffSinceMSW3 column
authoritySpeciesYear = authoritySpeciesYear,  # Include authoritySpeciesYear
iucnStatus = iucnStatus  # Include iucnStatus
) %>%
mutate(distribution_type = "subregionDistribution") %>%
select(sciName, regions_clean, distribution_type, possible, extinct, diffSinceMSW3, authoritySpeciesYear, iucnStatus)
# Combine the other species distribution columns, keeping relevant columns for later summaries
expanded_species_distribution <- species_df %>%
pivot_longer(cols = c(countryDistribution, continentDistribution, biogeographicRealm),
names_to = "distribution_type", values_to = "regions") %>%
filter(!is.na(regions)) %>%
separate_rows(regions, sep = "\\|") %>%
mutate(
possible = str_detect(regions, "\\?$"),
regions_clean = str_trim(str_remove(regions, "\\?$")),
sciName = sciName,
extinct = extinct,
diffSinceMSW3 = diffSinceMSW3,
authoritySpeciesYear = authoritySpeciesYear,
iucnStatus = iucnStatus
) %>%
select(sciName, regions_clean, distribution_type, possible, extinct, diffSinceMSW3, authoritySpeciesYear, iucnStatus)
# Add the processed subregion data to the expanded_species_distribution
expanded_species_distribution <- bind_rows(expanded_species_distribution, subregion_df)
# Identify and count endemic species per region
endemic_species_df <- expanded_species_distribution %>%
filter(!possible) %>%
group_by(sciName, distribution_type) %>%
filter(n_distinct(regions_clean) == 1) %>%
ungroup() %>%
group_by(regions_clean) %>%
summarise(endemic_species = n()) %>%
rename(region_name = regions_clean)
# Calculate the possible species count separately (distribution records followed by a question  mark)
possible_species_counts <- expanded_species_distribution %>%
filter(possible) %>%
group_by(regions_clean) %>%
summarise(possible_species_count = n()) %>%
rename(region_name = regions_clean)
# Calculate the confirmed counts for all other metrics, excluding possible species records
confirmed_species_counts <- expanded_species_distribution %>%
filter(!possible) %>%
group_by(regions_clean) %>%
summarise(
species_count = n(),
extinct_species_count = sum(extinct == 1, na.rm = TRUE),
living_species_count = n() - sum(extinct == 1, na.rm = TRUE),
new_since_MSW3 = sum(diffSinceMSW3 == 1, na.rm = TRUE),
new_descriptions_since_MSW3 = sum(diffSinceMSW3 == 1 & authoritySpeciesYear >= 2004, na.rm = TRUE),
IUCN_LC_species = sum(str_detect(iucnStatus, "^LC"), na.rm = TRUE),
IUCN_NT_species = sum(str_detect(iucnStatus, "^NT"), na.rm = TRUE),
IUCN_VU_species = sum(str_detect(iucnStatus, "^VU"), na.rm = TRUE),
IUCN_EN_species = sum(str_detect(iucnStatus, "^EN"), na.rm = TRUE),
IUCN_CR_species = sum(str_detect(iucnStatus, "^CR"), na.rm = TRUE),
IUCN_EW_species = sum(str_detect(iucnStatus, "^EW"), na.rm = TRUE),
IUCN_EX_species = sum(str_detect(iucnStatus, "^EX"), na.rm = TRUE),
IUCN_DD_species = sum(str_detect(iucnStatus, "^DD"), na.rm = TRUE),
IUCN_NE_species = sum(str_detect(iucnStatus, "^NE"), na.rm = TRUE)
) %>%
rename(region_name = regions_clean)
# Merge endemic species counts into confirmed species counts
confirmed_species_counts <- confirmed_species_counts %>%
left_join(endemic_species_df, by = "region_name") %>%
mutate(endemic_species = replace_na(endemic_species, 0))
# Merge possible species counts with confirmed species counts
species_counts <- confirmed_species_counts %>%
left_join(possible_species_counts, by = "region_name") %>%
replace_na(list(possible_species_count = 0))
# Summarize available names for MDD_type_country
available_names_country <- synonyms_df %>%
filter(MDD_nomenclature_status %in% c("available", "as_emended", "preoccupied", "nomen_novum", "partially_suppressed", "fully_suppressed")) %>%
group_by(MDD_type_country) %>%
summarise(available_names_country = n()) %>%
rename(region_name = MDD_type_country)
# Summarize available names for MDD_type_subregion
available_names_subregion <- synonyms_df %>%
filter(MDD_nomenclature_status %in% c("available", "as_emended", "preoccupied", "nomen_novum", "partially_suppressed", "fully_suppressed")) %>%
group_by(MDD_type_subregion) %>%
summarise(available_names_subregion = n()) %>%
rename(region_name = MDD_type_subregion)
# Merge the available names from country directly into the geographic data
geographic_data_df <- geographic_data_df %>%
left_join(available_names_country, by = "region_name") %>%
replace_na(list(available_names_country = 0))
# Merge the available names from subregion directly into the geographic data
geographic_data_df <- geographic_data_df %>%
left_join(available_names_subregion, by = "region_name") %>%
replace_na(list(available_names_subregion = 0))
# Summarize the total available names
geographic_data_df <- geographic_data_df %>%
mutate(available_names = available_names_country + available_names_subregion) %>%
select(-available_names_country, -available_names_subregion)
# Merge final counts into the geographic data, placing the available_names column before species_count
geography_summary_df <- geographic_data_df %>%
left_join(species_counts, by = "region_name") %>%
select(region_category, region_name, higher_country, higher_continent, higher_biogeographic_realm,
available_names, species_count, possible_species_count, extinct_species_count, living_species_count,
new_since_MSW3, new_descriptions_since_MSW3, endemic_species,
IUCN_LC_species, IUCN_NT_species, IUCN_VU_species, IUCN_EN_species,
IUCN_CR_species, IUCN_EW_species, IUCN_EX_species, IUCN_DD_species, IUCN_NE_species)
# Function to calculate and update available names for a specific biogeographic realm
update_available_names_for_realm <- function(realm_name, result_df, additional_filters = NULL) {
# Filter the dataframe to include relevant regions for the specified realm
filtered_df <- geography_summary_df %>%
filter(
(str_detect(region_category, "Country|Offshore Region|Continent Subregion") &
higher_biogeographic_realm == realm_name) |
(!is.null(additional_filters) &
(higher_country %in% additional_filters$country_values &
higher_biogeographic_realm == realm_name))
)
# Sum the available names for these filtered regions
available_names_sum <- sum(filtered_df$available_names, na.rm = TRUE)
# Update the available_names for the specified biogeographic realm in the geography_summary_df
geography_summary_df <- geography_summary_df %>%
mutate(
available_names = ifelse(
region_category == "Biogeographic Realm" & region_name == realm_name,
available_names_sum,
available_names
)
)
return(geography_summary_df)
}
# Calculate and upadate the available name counts for each biogeographic realm
# Afrotropic available name counts
geography_summary_df <- update_available_names_for_realm("Afrotropic", geography_summary_df)
# Antarctic available name counts
geography_summary_df <- update_available_names_for_realm("Antarctic", geography_summary_df)
# Australasia (including Indonesian subregions in Australasia) available name counts
geography_summary_df <- update_available_names_for_realm("Australasia", geography_summary_df,
additional_filters = list(country_values = c("Indonesia")))
# Indomalaya (including Indonesian and Chinese subregions in Indomalaya) available name counts
geography_summary_df <- update_available_names_for_realm("Indomalaya", geography_summary_df,
additional_filters = list(country_values = c("Indonesia", "China")))
# Nearctic (including Mexican subregions in the Nearctic) available name counts
geography_summary_df <- update_available_names_for_realm("Nearctic", geography_summary_df,
additional_filters = list(country_values = c("Mexico")))
# Neotropic (including Mexican subregions in the Neotropics) available name counts
geography_summary_df <- update_available_names_for_realm("Neotropic", geography_summary_df,
additional_filters = list(country_values = c("Mexico")))
# Oceania (Biorealm) available name counts
geography_summary_df <- update_available_names_for_realm("Oceania (Biorealm)", geography_summary_df)
# Palearctic (including Chinese subregions in the Palearctic) available name counts
geography_summary_df <- update_available_names_for_realm("Palearctic", geography_summary_df,
additional_filters = list(country_values = c("China")))
# Function to calculate and update available names for each continent
update_available_names_for_continent <- function(continent_name, geography_summary_df, additional_filters = NULL) {
# Filter the dataframe to include relevant regions for the specified continent
filtered_df <- geography_summary_df %>%
filter(
(str_detect(region_category, "Country|Offshore Region|Continent Subregion") &
higher_continent == continent_name) |
(!is.null(additional_filters) &
(higher_country %in% additional_filters$country_values &
higher_continent == continent_name))
)
# Sum the available names for these filtered regions
available_names_sum <- sum(filtered_df$available_names, na.rm = TRUE)
# Update the available_names for the specified continent in the geography_summary_df
geography_summary_df <- geography_summary_df %>%
mutate(
available_names = ifelse(
region_category == "Continent" & region_name == continent_name,
available_names_sum,
available_names
)
)
return(geography_summary_df)
}
# Calculate and update the available names for each continent
# Africa available name counts
geography_summary_df <- update_available_names_for_continent("Africa", geography_summary_df)
# Antarctica available name counts
geography_summary_df <- update_available_names_for_continent("Antarctica", geography_summary_df)
# Asia (including Indonesian and Russian subregions in Asia and all of Turkey)
geography_summary_df <- update_available_names_for_continent("Asia", geography_summary_df,
additional_filters = list(country_values = c("Indonesia", "Russia", "Turkey")))
# Europe (including Russian subregions in Europe) available name counts
geography_summary_df <- update_available_names_for_continent("Europe", geography_summary_df,
additional_filters = list(country_values = c("Russia")))
# North America available name counts
geography_summary_df <- update_available_names_for_continent("North America", geography_summary_df)
# Oceania (Continent) (including Indonesian subregions in Oceania) available name counts
geography_summary_df <- update_available_names_for_continent("Oceania (Continent)", geography_summary_df,
additional_filters = list(country_values = c("Indonesia")))
# South America available name counts
geography_summary_df <- update_available_names_for_continent("South America", geography_summary_df)
# View the geography_summary_df
print(geography_summary_df)
# Saving the geographic data summary as a CSV file
write.csv(geography_summary_df, "supplementary_files\\geographic_data_summary.csv", row.names = FALSE)
######nomenclature_summary_df Supplement Table######
# Summarizing the nomenclature data from the synonym sheet for a supplemental table
# Load packages
#library(dplyr)
#library(readxl)
# Load the synonym sheet from an excel file
#synonyms_df <- read.csv("base_files\\MDD_v2.0\\MDD_v2.0\\Species_Syn_v2.0.csv")
# Clean the data and use MDD_syn_ID as the unique identifier
synonyms_df_cleaned <- synonyms_df %>%
mutate(
MDD_type_latitude = str_trim(str_replace_all(MDD_type_latitude, "\\s+", "")),
MDD_type_longitude = str_trim(str_replace_all(MDD_type_longitude, "\\s+", "")),
MDD_authority_citation = str_trim(str_replace_all(MDD_authority_citation, "[^[:print:]]", "")),
MDD_unchecked_authority_citation = str_trim(str_replace_all(MDD_unchecked_authority_citation, "[^[:print:]]", "")),
MDD_original_type_locality = str_trim(str_replace_all(MDD_original_type_locality, "[^[:print:]]", "")),
MDD_unchecked_type_locality = str_trim(str_replace_all(MDD_unchecked_type_locality, "[^[:print:]]", "")),
MDD_author = str_trim(str_replace_all(MDD_author, "[^[:print:]]", "")),
MDD_original_combination = str_trim(str_replace_all(MDD_original_combination, "[^[:print:]]", "")),
MDD_original_rank = str_trim(str_replace_all(MDD_original_rank, "[^[:print:]]", "")),
MDD_type_kind = str_trim(str_replace_all(MDD_type_kind, "[^[:print:]]", "")),
MDD_type_specimen_link = str_trim(str_replace_all(MDD_type_specimen_link, "[^[:print:]]", "")),
MDD_type_latitude = as.numeric(MDD_type_latitude),
MDD_type_longitude = as.numeric(MDD_type_longitude)
)
# Separate rows based on multiple values in MDD_nomenclature_status, but retain the original MDD_syn_ID
synonyms_df_separated <- synonyms_df_cleaned %>%
separate_rows(MDD_nomenclature_status, sep = "\\|") %>%
mutate(MDD_nomenclature_status = str_trim(MDD_nomenclature_status))
# Create flagged_synonyms_df using the separated data and retain MDD_syn_ID
flagged_synonyms_df <- synonyms_df_separated %>%
mutate(
type_coordinates_flag = if_else(!is.na(MDD_type_latitude) & !is.na(MDD_type_longitude) &
MDD_type_latitude >= -90 & MDD_type_latitude <= 90 &
MDD_type_longitude >= -180 & MDD_type_longitude <= 180, TRUE, FALSE),
original_type_locality_flag = if_else(!is.na(MDD_original_type_locality) & MDD_original_type_locality != "", TRUE, FALSE),
authority_citation_flag = if_else(!is.na(MDD_authority_citation) & MDD_authority_citation != "" |
!is.na(MDD_unchecked_authority_citation) & MDD_unchecked_authority_citation != "", TRUE, FALSE),
type_locality_flag = if_else(!is.na(MDD_original_type_locality) & MDD_original_type_locality != "" |
!is.na(MDD_unchecked_type_locality) & MDD_unchecked_type_locality != "", TRUE, FALSE),
authority_author_flag = if_else(!is.na(MDD_author) & MDD_author != "", TRUE, FALSE),
authority_year_flag = if_else(!is.na(MDD_year), TRUE, FALSE),
original_combination_flag = if_else(!is.na(MDD_original_combination) & MDD_original_combination != "", TRUE, FALSE),
original_rank_flag = if_else(!is.na(MDD_original_rank) & MDD_original_rank != "", TRUE, FALSE),
verified_authority_citation_flag = if_else(!is.na(MDD_authority_citation) & MDD_authority_citation != "", TRUE, FALSE),
authority_page_flag = if_else(!is.na(MDD_authority_page) & MDD_authority_page != "", TRUE, FALSE),
authority_link_flag = if_else(!is.na(MDD_authority_link) & MDD_authority_link != "", TRUE, FALSE),
authority_page_link_flag = if_else(!is.na(MDD_authority_page_link) & MDD_authority_page_link != "", TRUE, FALSE),
type_specimen_flag = if_else(!is.na(MDD_type_kind) & MDD_type_kind != "", TRUE, FALSE),
type_specimen_link_flag = if_else(!is.na(MDD_type_specimen_link) & MDD_type_specimen_link != "", TRUE, FALSE)
)
# Group by MDD_syn_ID to avoid overcounting after splitting and retain MDD_validity and MDD_nomenclature_status
MDD_nomenclature_status
# Group by MDD_syn_ID to avoid overcounting after splitting and retain MDD_validity and MDD_nomenclature_status
flagged_synonyms_df_grouped <- flagged_synonyms_df %>%
group_by(MDD_syn_ID, MDD_validity, MDD_nomenclature_status) %>%
summarise(
authority_author_flag = max(authority_author_flag),
authority_year_flag = max(authority_year_flag),
type_coordinates_flag = max(type_coordinates_flag),
original_type_locality_flag = max(original_type_locality_flag),
original_combination_flag = max(original_combination_flag),
original_rank_flag = max(original_rank_flag),
authority_citation_flag = max(authority_citation_flag),
verified_authority_citation_flag = max(verified_authority_citation_flag),
authority_page_flag = max(authority_page_flag),
authority_link_flag = max(authority_link_flag),
authority_page_link_flag = max(authority_page_link_flag),
type_locality_flag = max(type_locality_flag),
type_specimen_flag = max(type_specimen_flag),
type_specimen_link_flag = max(type_specimen_link_flag),
MDD_year = max(MDD_year),
MDD_original_type_locality = max(MDD_original_type_locality)
)
# Combine the flagged columns with the original synonym data for easy filtering
flagged_synonyms_df_grouped <- flagged_synonyms_df_grouped %>%
select(MDD_syn_ID, MDD_validity, MDD_nomenclature_status, authority_author_flag, authority_year_flag,
original_combination_flag, original_rank_flag, authority_citation_flag,
verified_authority_citation_flag, authority_page_flag, authority_link_flag,
authority_page_link_flag, type_locality_flag, original_type_locality_flag, type_coordinates_flag,
type_specimen_flag, type_specimen_link_flag, MDD_year, MDD_original_type_locality)
# Now create the summary by applying the flags with the correct filters
val_nom_summary_df <- val_nom_summary_df %>%
rowwise() %>%
mutate(
# Apply the filter using both MDD_validity and MDD_nomenclature_status to ensure only relevant rows are counted
authority_author_count = sum((flagged_synonyms_df_grouped$authority_author_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_year_count = sum((flagged_synonyms_df_grouped$authority_year_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
year_since_2000_count = sum(flagged_synonyms_df_grouped$MDD_year >= 2000 &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_combination_total = sum((flagged_synonyms_df_grouped$original_combination_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_rank_count = sum((flagged_synonyms_df_grouped$original_rank_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_citation_count = sum((flagged_synonyms_df_grouped$authority_citation_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
verified_authority_citation_count = sum((flagged_synonyms_df_grouped$verified_authority_citation_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_page_count = sum((flagged_synonyms_df_grouped$authority_page_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_link_count = sum((flagged_synonyms_df_grouped$authority_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_page_link_count = sum((flagged_synonyms_df_grouped$authority_page_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_locality_count = sum((flagged_synonyms_df_grouped$type_locality_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_type_locality_count = sum((flagged_synonyms_df_grouped$original_type_locality_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_coordinates_count = sum((flagged_synonyms_df_grouped$type_coordinates_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_specimen_count = sum((flagged_synonyms_df_grouped$type_specimen_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_specimen_link_count = sum((flagged_synonyms_df_grouped$type_specimen_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE)
) %>%
ungroup()
# Summarizing based on validity status and other conditions
val_nom_summary_df <- flagged_synonyms_df_grouped %>%
group_by(MDD_validity, MDD_nomenclature_status) %>%
summarise(
total_names = n(),  # Count number of rows for this group
authority_author_count = sum(authority_author_flag, na.rm = TRUE),
authority_year_count = sum(authority_year_flag, na.rm = TRUE),
year_since_2000_count = sum(MDD_year >= 2000, na.rm = TRUE),
original_combination_total = sum(original_combination_flag, na.rm = TRUE),
original_rank_count = sum(original_rank_flag, na.rm = TRUE),
authority_citation_count = sum(authority_citation_flag, na.rm = TRUE),
verified_authority_citation_count = sum(verified_authority_citation_flag, na.rm = TRUE),
authority_page_count = sum(authority_page_flag, na.rm = TRUE),
authority_link_count = sum(authority_link_flag, na.rm = TRUE),
authority_page_link_count = sum(authority_page_link_flag, na.rm = TRUE),
type_locality_count = sum(type_locality_flag, na.rm = TRUE),
original_type_locality_count = sum(original_type_locality_flag, na.rm = TRUE),
type_coordinates_count = sum(type_coordinates_flag, na.rm = TRUE),
type_specimen_count = sum(type_specimen_flag, na.rm = TRUE),
type_specimen_link_count = sum(type_specimen_link_flag, na.rm = TRUE)
)
# Summarizing based on validity status and other conditions
val_nom_summary_df <- flagged_synonyms_df_grouped %>%
group_by(MDD_validity, MDD_nomenclature_status) %>%
summarise(
total_names = n(),  # Count number of rows for this group
authority_author_count = sum(authority_author_flag, na.rm = TRUE),
authority_year_count = sum(authority_year_flag, na.rm = TRUE),
year_since_2000_count = sum(MDD_year >= 2000, na.rm = TRUE),
original_combination_total = sum(original_combination_flag, na.rm = TRUE),
original_rank_count = sum(original_rank_flag, na.rm = TRUE),
authority_citation_count = sum(authority_citation_flag, na.rm = TRUE),
verified_authority_citation_count = sum(verified_authority_citation_flag, na.rm = TRUE),
authority_page_count = sum(authority_page_flag, na.rm = TRUE),
authority_link_count = sum(authority_link_flag, na.rm = TRUE),
authority_page_link_count = sum(authority_page_link_flag, na.rm = TRUE),
type_locality_count = sum(type_locality_flag, na.rm = TRUE),
original_type_locality_count = sum(original_type_locality_flag, na.rm = TRUE),
type_coordinates_count = sum(type_coordinates_flag, na.rm = TRUE),
type_specimen_count = sum(type_specimen_flag, na.rm = TRUE),
type_specimen_link_count = sum(type_specimen_link_flag, na.rm = TRUE)
)
# Now create the summary by applying the flags with the correct filters
val_nom_summary_df <- val_nom_summary_df %>%
rowwise() %>%
mutate(
# Apply the filter using both MDD_validity and MDD_nomenclature_status to ensure only relevant rows are counted
authority_author_count = sum((flagged_synonyms_df_grouped$authority_author_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_year_count = sum((flagged_synonyms_df_grouped$authority_year_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
year_since_2000_count = sum(flagged_synonyms_df_grouped$MDD_year >= 2000 &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_combination_total = sum((flagged_synonyms_df_grouped$original_combination_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_rank_count = sum((flagged_synonyms_df_grouped$original_rank_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_citation_count = sum((flagged_synonyms_df_grouped$authority_citation_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
verified_authority_citation_count = sum((flagged_synonyms_df_grouped$verified_authority_citation_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_page_count = sum((flagged_synonyms_df_grouped$authority_page_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_link_count = sum((flagged_synonyms_df_grouped$authority_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_page_link_count = sum((flagged_synonyms_df_grouped$authority_page_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_locality_count = sum((flagged_synonyms_df_grouped$type_locality_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_type_locality_count = sum((flagged_synonyms_df_grouped$original_type_locality_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_coordinates_count = sum((flagged_synonyms_df_grouped$type_coordinates_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_specimen_count = sum((flagged_synonyms_df_grouped$type_specimen_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_specimen_link_count = sum((flagged_synonyms_df_grouped$type_specimen_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE)
) %>%
ungroup()
# Create validity summary dataframe with status_type and status columns
validity_df <- flagged_synonyms_df_grouped %>%
mutate(
status_type = "Validity Status",  # Set the status type
status = MDD_validity  # Set the status as the values from MDD_validity
) %>%
select(status_type, status, everything())  # Reorder columns
# Create nomenclature summary dataframe with status_type and status columns
nomenclature_df <- flagged_synonyms_df_grouped %>%
mutate(
status_type = "Nomenclature Status",  # Set the status type
status = MDD_nomenclature_status  # Set the status as the values from MDD_nomenclature_status
) %>%
select(status_type, status, everything())  # Reorder columns
# Combine the validity and nomenclature dataframes into one
val_nom_summary_df <- bind_rows(validity_df, nomenclature_df)
# Now create the summary by applying the flags with the correct filters
val_nom_summary_df <- val_nom_summary_df %>%
rowwise() %>%
mutate(
# Apply the filter using both MDD_validity and MDD_nomenclature_status to ensure only relevant rows are counted
authority_author_count = sum((flagged_synonyms_df_grouped$authority_author_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_year_count = sum((flagged_synonyms_df_grouped$authority_year_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
year_since_2000_count = sum(flagged_synonyms_df_grouped$MDD_year >= 2000 &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_combination_total = sum((flagged_synonyms_df_grouped$original_combination_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_rank_count = sum((flagged_synonyms_df_grouped$original_rank_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_citation_count = sum((flagged_synonyms_df_grouped$authority_citation_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
verified_authority_citation_count = sum((flagged_synonyms_df_grouped$verified_authority_citation_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_page_count = sum((flagged_synonyms_df_grouped$authority_page_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_link_count = sum((flagged_synonyms_df_grouped$authority_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
authority_page_link_count = sum((flagged_synonyms_df_grouped$authority_page_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_locality_count = sum((flagged_synonyms_df_grouped$type_locality_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
original_type_locality_count = sum((flagged_synonyms_df_grouped$original_type_locality_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_coordinates_count = sum((flagged_synonyms_df_grouped$type_coordinates_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_specimen_count = sum((flagged_synonyms_df_grouped$type_specimen_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE),
type_specimen_link_count = sum((flagged_synonyms_df_grouped$type_specimen_link_flag == TRUE) &
(flagged_synonyms_df_grouped$MDD_validity == status |
str_detect(flagged_synonyms_df_grouped$MDD_nomenclature_status, fixed(status))), na.rm = TRUE)
) %>%
ungroup()
